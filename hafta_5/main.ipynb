{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kütüphaneleri içe aktarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphanelerin yüklenmesi\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\"\"\"\n",
    "Bu kod bloğu, derin öğrenme modeli oluşturmak ve IMDB veri setini işlemek için gerekli kütüphaneleri import eder.\n",
    "\n",
    "Imports:\n",
    "    numpy as np: Sayısal işlemler ve dizi manipülasyonları için kullanılır.\n",
    "    tensorflow.keras: Derin öğrenme modellerini oluşturmak ve eğitmek için yüksek seviyeli API sağlar.\n",
    "    tensorflow.keras.datasets.imdb: IMDB film yorumları veri setini yüklemek için kullanılır.\n",
    "    tensorflow.keras.models.Sequential: Katmanları sıralı bir şekilde ekleyerek model oluşturmayı sağlar.\n",
    "    tensorflow.keras.layers.Dense, Embedding, Flatten: Model mimarisinde kullanılacak katman türlerini içerir.\n",
    "    tensorflow.keras.preprocessing.sequence.pad_sequences: Dizileri eşit uzunlukta hale getirmek için kullanılır.\n",
    "\n",
    "Returns:\n",
    "    None\n",
    "\n",
    "Not:\n",
    "    Bu importlar, bir duygu analizi modeli oluşturmak için IMDB veri setini kullanacak bir projenin temelini oluşturur.\n",
    "\"\"\"\n",
    "print(\"Gerekli kütüphaneler başarıyla yüklendi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri kümesi işlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setinin yüklenmesi\n",
    "\"\"\"\n",
    "Bu kod bloğu, IMDB film yorumları veri setini yükler ve eğitim ve test verilerine ayırır.\n",
    "\n",
    "Args:\n",
    "    num_words (int): Veri setinde kullanılacak en sık kullanılan kelime sayısı\n",
    "\n",
    "Returns:\n",
    "    tuple: İki tuple içeren bir tuple:\n",
    "        - (X_train, y_train): Eğitim verileri ve etiketleri\n",
    "        - (X_test, y_test): Test verileri ve etiketleri\n",
    "\n",
    "X_train ve X_test: Film yorumlarının kelime dizileri (liste olarak)\n",
    "y_train ve y_test: Yorumların duygu etiketleri (0: negatif, 1: pozitif)\n",
    "\n",
    "Not:\n",
    "    Bu fonksiyon, veri setini otomatik olarak eğitim ve test setlerine ayırır.\n",
    "    num_words parametresi, veri setinde kullanılacak en sık kelime sayısını sınırlar.\n",
    "\"\"\"\n",
    "\n",
    "print(\"IMDB veri kümesi yükleniyor...\")\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"Veri kümesi başarıyla yüklendi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri kümesinin incelenmesi\n",
    "\"\"\"\n",
    "Bu kod bloğu, yüklenen IMDB veri kümesinin temel özelliklerini inceler ve gösterir.\n",
    "\n",
    "Args:\n",
    "    None\n",
    "\n",
    "Returns:\n",
    "    None\n",
    "\n",
    "Çıktı:\n",
    "    - Eğitim veri seti boyutu\n",
    "    - Test veri seti boyutu\n",
    "    - İlk eğitim örneğinin içeriği\n",
    "\n",
    "Not:\n",
    "    Bu inceleme, veri kümesinin yapısını ve boyutunu anlamak için önemlidir.\n",
    "    İlk eğitim örneği, bir film yorumunun nasıl temsil edildiğini gösterir.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Eğitim veri seti boyutu: {len(X_train)}\")\n",
    "print(f\"Test veri seti boyutu: {len(X_test)}\")\n",
    "print(f\"İlk eğitim örneği:\")\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri kümesindeki kelimeleri kelime dağarcığına çevirme\n",
    "\"\"\"\n",
    "Bu kod bloğu, IMDB veri kümesindeki kelimelerin indekslerini içeren bir sözlük yükler.\n",
    "\n",
    "word_index (dict): Kelimeleri ve karşılık gelen indekslerini içeren bir sözlük\n",
    "\n",
    "Not:\n",
    "    Bu sözlük, kelimeler ve onların sayısal temsilleri arasında bir eşleştirme sağlar.\n",
    "    Bu, daha sonra film yorumlarındaki sayısal indeksleri anlamlı kelimelere çevirmek için kullanılabilir.\n",
    "\"\"\"\n",
    "word_index = imdb.get_word_index()\n",
    "print(\"Kelime indeksi yüklendi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ters çevirme işlemi ile indeksleri kelimelere dönüştürme\n",
    "\"\"\"\n",
    "Bu kod bloğu, sayısal indeksleri kelimelere dönüştürmek için bir sözlük ve bir fonksiyon oluşturur.\n",
    "\n",
    "reverse_word_index (dict): İndeksleri kelimelere eşleyen ters çevrilmiş sözlük\n",
    "decode_review (function): Sayısal indeks listesini okunabilir metne dönüştüren fonksiyon\n",
    "\n",
    "Not:\n",
    "    - reverse_word_index, word_index sözlüğünün ters çevrilmiş halidir.\n",
    "    - decode_review fonksiyonu, bir film yorumunu sayısal indekslerden okunabilir metne çevirir.\n",
    "    - İndekslerden 3 çıkarılır çünkü IMDB veri setinde 0, 1, 2 indeksleri özel anlamlara sahiptir.\n",
    "\"\"\"\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text])\n",
    "ilk_eleman = next(iter(reverse_word_index.items()))\n",
    "print(ilk_eleman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bu kod bloğu, eğitim setindeki ilk film yorumunu okunabilir formatta gösterir.\n",
    "Çıktı:\n",
    "    İlk eğitim örneğinin okunabilir metin hali\n",
    "\n",
    "Not:\n",
    "    - Bu, daha önce tanımlanan decode_review fonksiyonunu kullanır.\n",
    "    - X_train[0], eğitim setindeki ilk film yorumunun sayısal indeks listesidir.\n",
    "    - Çıktı, bu sayısal indekslerin kelimelere dönüştürülmüş halidir.\n",
    "\"\"\"\n",
    "print(\"İlk eğitim örneğinin orijinal hali:\")\n",
    "print(decode_review(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri ön işleme: Tüm yorumları aynı uzunluğa getirmek\n",
    "\"\"\"\n",
    "Bu kod bloğu, film yorumlarını aynı uzunluğa getirerek veri ön işleme yapar.\n",
    "maxlen (int): Her yorumun maksimum uzunluğu\n",
    "X_train (numpy.ndarray): Ön işleme yapılmış eğitim verileri\n",
    "X_test (numpy.ndarray): Ön işleme yapılmış test verileri\n",
    "\n",
    "Not:\n",
    "    - pad_sequences fonksiyonu, tüm yorumları aynı uzunluğa (maxlen) getirir.\n",
    "    - Kısa yorumlar sıfırlarla doldurulur, uzun yorumlar kesilir.\n",
    "    - Bu işlem, modelin sabit boyutlu girdiler alabilmesi için gereklidir.\n",
    "\"\"\"\n",
    "print(\"Veri ön işleme yapılıyor...\")\n",
    "maxlen = 500\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "print(\"Veri ön işleme tamamlandı.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin oluşturulması\n",
    "\"\"\"\n",
    "Bu kod bloğu, duygu analizi için bir sinir ağı modeli oluşturur.\n",
    "\n",
    "model (Sequential): Oluşturulan Keras Sequential model\n",
    "\n",
    "Not:\n",
    "    - Model, bir Embedding katmanı, bir Flatten katmanı ve bir Dense katmandan oluşur.\n",
    "    - Embedding katmanı, kelime indekslerini yoğun vektörlere dönüştürür.\n",
    "    - Flatten katmanı, çok boyutlu girdiyi düzleştirir.\n",
    "    - Dense katman, son sınıflandırma işlemini gerçekleştirir.\n",
    "    - 'sigmoid' aktivasyon fonksiyonu, çıktıyı 0 ile 1 arasında bir olasılığa dönüştürür.\n",
    "\"\"\"\n",
    "print(\"Model oluşturuluyor...\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bu kod bloğu, oluşturulan modelin özetini gösterir.\n",
    "Çıktı:\n",
    "    Modelin katmanları, parametreleri ve toplam parametre sayısı hakkında detaylı bilgi\n",
    "\n",
    "Not:\n",
    "    - model.summary() fonksiyonu, modelin yapısını, her katmanın çıktı şeklini ve parametre sayısını gösterir.\n",
    "    - Bu özet, modelin karmaşıklığını ve bellek gereksinimlerini anlamak için çok faydalıdır.\n",
    "\"\"\"\n",
    "print(\"Model özeti:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model eğitme işlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin derlenmesi\n",
    "\"\"\"\n",
    "Bu kod bloğu, oluşturulan modeli derler ve eğitim için hazırlar.\n",
    "Not:\n",
    "    - model.compile() fonksiyonu, modelin eğitim sürecini yapılandırır.\n",
    "    - optimizer='adam': Adam optimizasyon algoritması kullanılacak.\n",
    "    - loss='binary_crossentropy': İkili sınıflandırma için uygun kayıp fonksiyonu.\n",
    "    - metrics=['accuracy']: Eğitim sırasında doğruluk metriği izlenecek.\n",
    "\"\"\"\n",
    "print(\"Model derleniyor...\")\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"Model derleme tamamlandı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin eğitilmesi\n",
    "\"\"\"\n",
    "Bu kod bloğu, oluşturulan modeli eğitir.\n",
    "\n",
    "X_train (numpy.ndarray): Eğitim verileri\n",
    "y_train (numpy.ndarray): Eğitim etiketleri\n",
    "history (keras.callbacks.History): Eğitim sürecinin geçmişi\n",
    "\n",
    "Not:\n",
    "    - model.fit() fonksiyonu, modeli verilen veriler üzerinde eğitir.\n",
    "    - epochs=5: Model, veri seti üzerinde 5 kez tekrarlanacak.\n",
    "    - batch_size=128: Her iterasyonda 128 örnek işlenecek.\n",
    "    - validation_split=0.2: Eğitim verilerinin %20'si doğrulama için ayrılacak.\n",
    "\"\"\"\n",
    "print(\"Model eğitiliyor...\")\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_split=0.2)\n",
    "print(\"Model eğitim tamamlandı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin değerlendirilmesi\n",
    "\n",
    "\"\"\"\n",
    "Bu kod bloğu, eğitilmiş modeli test veri seti üzerinde değerlendirir.\n",
    "\n",
    "Çıktı:\n",
    "    - Test Loss: Modelin test veri seti üzerindeki kayıp değeri\n",
    "    - Test Accuracy: Modelin test veri seti üzerindeki doğruluk oranı\n",
    "\n",
    "Not:\n",
    "    - model.evaluate() fonksiyonu, modeli verilen veri seti üzerinde değerlendirir.\n",
    "    - Kayıp (loss) değeri, modelin tahminlerinin gerçek değerlerden ne kadar uzak olduğunu gösterir.\n",
    "    - Doğruluk (accuracy) değeri, modelin doğru tahmin ettiği örneklerin oranını gösterir.\n",
    "\"\"\"\n",
    "print(\"Model test verisi üzerinde değerlendiriliyor...\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeli elle test etme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonksiyon tanımları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_review():\n",
    "    \"\"\"\n",
    "    Kullanıcıdan film yorumu alır.\n",
    "\n",
    "    Returns:\n",
    "        str: Kullanıcının girdiği film yorumu\n",
    "\n",
    "    Not:\n",
    "        - Kullanıcıya bir giriş istemi sunar.\n",
    "        - 'q' girişi, programdan çıkış için kullanılır.\n",
    "    \"\"\"\n",
    "    return input(\"Lütfen bir film yorumu girin (Çıkmak için 'q' yazın): \")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Metni kelimelere ayırır.\n",
    "\n",
    "    Args:\n",
    "        text (str): İşlenecek metin\n",
    "\n",
    "    Returns:\n",
    "        list: Metindeki kelimelerin listesi\n",
    "\n",
    "    Not:\n",
    "        - Keras'ın text_to_word_sequence fonksiyonunu kullanır.\n",
    "        - Bu fonksiyon, metni küçük harflere çevirir, noktalama işaretlerini kaldırır ve kelimelere ayırır.\n",
    "    \"\"\"\n",
    "    return keras.preprocessing.text.text_to_word_sequence(text)\n",
    "\n",
    "def tokenize_words(tokens):\n",
    "    \"\"\"\n",
    "    Kelimeleri sayısal indekslere dönüştürür.\n",
    "\n",
    "    Args:\n",
    "        tokens (list): Kelime listesi\n",
    "\n",
    "    Returns:\n",
    "        list: Kelimelerin sayısal indeks karşılıkları\n",
    "\n",
    "    Not:\n",
    "        - word_index sözlüğünü kullanarak her kelimeyi bir sayıya dönüştürür.\n",
    "        - Sözlükte olmayan kelimeler için 1 değerini kullanır (genellikle bilinmeyen kelime indeksi).\n",
    "    \"\"\"\n",
    "    return [word_index.get(word, 1) for word in tokens]\n",
    "\n",
    "def limit_token_range(tokens):\n",
    "    \"\"\"\n",
    "    Token değerlerini 10000'in altında tutar.\n",
    "\n",
    "    Args:\n",
    "        tokens (list): Sayısal token listesi\n",
    "\n",
    "    Returns:\n",
    "        list: 10000'in altındaki değerlere sınırlandırılmış token listesi\n",
    "\n",
    "    Not:\n",
    "        - 10000'den büyük indeksleri 1'e çevirir.\n",
    "        - Bu, modelin kelime dağarcığı boyutunu sınırlar ve aşırı büyük indeksleri engeller.\n",
    "    \"\"\"\n",
    "    return [t if t < 10000 else 1 for t in tokens]\n",
    "\n",
    "def pad_tokens(tokens):\n",
    "    \"\"\"\n",
    "    Token dizisini sabit uzunluğa getirir.\n",
    "\n",
    "    Args:\n",
    "        tokens (list): Sayısal token listesi\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Sabit uzunluğa getirilmiş token dizisi\n",
    "\n",
    "    Not:\n",
    "        - Keras'ın pad_sequences fonksiyonunu kullanır.\n",
    "        - maxlen değişkeni, dizinin hedef uzunluğunu belirtir.\n",
    "        - Kısa diziler 0 ile doldurulur, uzun diziler kesilir.\n",
    "    \"\"\"\n",
    "    return pad_sequences([tokens], maxlen=maxlen)\n",
    "\n",
    "def encode_review(text):\n",
    "    \"\"\"\n",
    "    Yorumu model için uygun formata dönüştürür.\n",
    "\n",
    "    Args:\n",
    "        text (str): Orijinal yorum metni\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Model için hazırlanmış, kodlanmış yorum\n",
    "\n",
    "    Not:\n",
    "        - Metni işlemek için önceki fonksiyonları sırayla çağırır.\n",
    "        - Son çıktı, modelin beklediği formatta bir numpy dizisidir.\n",
    "    \"\"\"\n",
    "    tokens = preprocess_text(text)\n",
    "    tokens = tokenize_words(tokens)\n",
    "    tokens = limit_token_range(tokens)\n",
    "    return pad_tokens(tokens)\n",
    "\n",
    "def predict_sentiment(encoded_review):\n",
    "    \"\"\"\n",
    "    Kodlanmış yorum için duygu tahmini yapar.\n",
    "\n",
    "    Args:\n",
    "        encoded_review (numpy.ndarray): Kodlanmış yorum\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Modelin tahmin sonucu\n",
    "\n",
    "    Not:\n",
    "        - Önceden eğitilmiş modeli kullanarak tahmin yapar.\n",
    "        - Sonuç, yorumun pozitif olma olasılığını içerir.\n",
    "    \"\"\"\n",
    "    return model.predict(encoded_review)\n",
    "\n",
    "def print_prediction(review, prediction):\n",
    "    \"\"\"\n",
    "    Tahmin sonucunu ekrana yazdırır.\n",
    "\n",
    "    Args:\n",
    "        review (str): Orijinal yorum metni\n",
    "        prediction (numpy.ndarray): Model tahmini\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Not:\n",
    "        - Orijinal yorumu ve pozitif olma olasılığını yazdırır.\n",
    "        - Olasılık 4 ondalık basamağa yuvarlanır.\n",
    "    \"\"\"\n",
    "    print(f\"\\nYorum: {review}\")\n",
    "    print(f\"Pozitif olma olasılığı: {prediction[0][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elle test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Film yorumları için duygu analizi uygulaması başlatılıyor...\")\n",
    "while True:\n",
    "    review = get_user_review()\n",
    "    if review.lower() == 'q':\n",
    "        print(\"Uygulama sonlandırılıyor...\")\n",
    "        break\n",
    "    \n",
    "    encoded_review = encode_review(review)\n",
    "    prediction = predict_sentiment(encoded_review)\n",
    "    print_prediction(review, prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

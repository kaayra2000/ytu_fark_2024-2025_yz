{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kütüphaneleri içe aktarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphanelerin yüklenmesi\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Conv1D, GlobalMaxPooling1D, Dropout, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\"\"\"\n",
    "Bu kod bloğu, derin öğrenme modeli oluşturmak ve IMDB veri setini işlemek için gerekli kütüphaneleri import eder.\n",
    "\n",
    "Imports:\n",
    "    tensorflow.keras: Derin öğrenme modellerini oluşturmak ve eğitmek için yüksek seviyeli API sağlar.\n",
    "    tensorflow.keras.datasets.imdb: IMDB film yorumları veri setini yüklemek için kullanılır.\n",
    "    tensorflow.keras.models.Sequential: Katmanları sıralı bir şekilde ekleyerek model oluşturmayı sağlar.\n",
    "    tensorflow.keras.layers.Dense, Embedding, Flatten: Model mimarisinde kullanılacak katman türlerini içerir.\n",
    "    tensorflow.keras.preprocessing.sequence.pad_sequences: Dizileri eşit uzunlukta hale getirmek için kullanılır.\n",
    "\n",
    "Returns:\n",
    "    None\n",
    "\n",
    "Not:\n",
    "    Bu importlar, bir duygu analizi modeli oluşturmak için IMDB veri setini kullanacak bir projenin temelini oluşturur.\n",
    "\"\"\"\n",
    "print(\"Gerekli kütüphaneler başarıyla yüklendi.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri kümesi işlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setinin yüklenmesi\n",
    "\"\"\"\n",
    "Bu kod bloğu, IMDB film yorumları veri setini yükler ve eğitim ve test verilerine ayırır.\n",
    "\n",
    "Args:\n",
    "    num_words (int): Veri setinde kullanılacak en sık kullanılan kelime sayısı\n",
    "\n",
    "Returns:\n",
    "    tuple: İki tuple içeren bir tuple:\n",
    "        - (X_train, y_train): Eğitim verileri ve etiketleri\n",
    "        - (X_test, y_test): Test verileri ve etiketleri\n",
    "\n",
    "X_train ve X_test: Film yorumlarının kelime dizileri (liste olarak)\n",
    "y_train ve y_test: Yorumların duygu etiketleri (0: negatif, 1: pozitif)\n",
    "\n",
    "Not:\n",
    "    Bu fonksiyon, veri setini otomatik olarak eğitim ve test setlerine ayırır.\n",
    "    num_words parametresi, veri setinde kullanılacak en sık kelime sayısını sınırlar.\n",
    "\"\"\"\n",
    "# veri kümesindeki en büyük indeksi bulma (kelime sayısı)\n",
    "max_index = 10000\n",
    "print(\"IMDB veri kümesi yükleniyor...\")\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_index)\n",
    "print(\"Veri kümesi başarıyla yüklendi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri kümesinin incelenmesi\n",
    "\"\"\"\n",
    "Bu kod bloğu, yüklenen IMDB veri kümesinin temel özelliklerini inceler ve gösterir.\n",
    "\n",
    "Args:\n",
    "    None\n",
    "\n",
    "Returns:\n",
    "    None\n",
    "\n",
    "Çıktı:\n",
    "    - Eğitim veri seti boyutu\n",
    "    - Test veri seti boyutu\n",
    "    - İlk eğitim örneğinin içeriği\n",
    "\n",
    "Not:\n",
    "    Bu inceleme, veri kümesinin yapısını ve boyutunu anlamak için önemlidir.\n",
    "    İlk eğitim örneği, bir film yorumunun nasıl temsil edildiğini gösterir.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Eğitim veri seti boyutu: {len(X_train)}\")\n",
    "print(f\"Test veri seti boyutu: {len(X_test)}\")\n",
    "print(f\"İlk eğitim örneği:\")\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri kümesindeki kelimeleri kelime dağarcığına çevirme\n",
    "\"\"\"\n",
    "Bu kod bloğu, IMDB veri kümesindeki kelimelerin indekslerini içeren bir sözlük yükler.\n",
    "\n",
    "word_index (dict): Kelimeleri ve karşılık gelen indekslerini içeren bir sözlük\n",
    "\n",
    "Not:\n",
    "    Bu sözlük, kelimeler ve onların sayısal temsilleri arasında bir eşleştirme sağlar.\n",
    "    Bu, daha sonra film yorumlarındaki sayısal indeksleri anlamlı kelimelere çevirmek için kullanılabilir.\n",
    "\"\"\"\n",
    "word_index = imdb.get_word_index()\n",
    "print(\"Kelime indeksi yüklendi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ters çevirme işlemi ile indeksleri kelimelere dönüştürme\n",
    "\"\"\"\n",
    "Bu kod bloğu, sayısal indeksleri kelimelere dönüştürmek için bir sözlük ve bir fonksiyon oluşturur.\n",
    "\n",
    "reverse_word_index (dict): İndeksleri kelimelere eşleyen ters çevrilmiş sözlük\n",
    "decode_review (function): Sayısal indeks listesini okunabilir metne dönüştüren fonksiyon\n",
    "\n",
    "Not:\n",
    "    - reverse_word_index, word_index sözlüğünün ters çevrilmiş halidir.\n",
    "    - decode_review fonksiyonu, bir film yorumunu sayısal indekslerden okunabilir metne çevirir.\n",
    "    - İndekslerden 3 çıkarılır çünkü IMDB veri setinde 0, 1, 2 indeksleri özel anlamlara sahiptir.\n",
    "\"\"\"\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text])\n",
    "ilk_eleman = next(iter(reverse_word_index.items()))\n",
    "print(ilk_eleman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bu kod bloğu, eğitim setindeki ilk film yorumunu okunabilir formatta gösterir.\n",
    "Çıktı:\n",
    "    İlk eğitim örneğinin okunabilir metin hali\n",
    "\n",
    "Not:\n",
    "    - Bu, daha önce tanımlanan decode_review fonksiyonunu kullanır.\n",
    "    - X_train[0], eğitim setindeki ilk film yorumunun sayısal indeks listesidir.\n",
    "    - Çıktı, bu sayısal indekslerin kelimelere dönüştürülmüş halidir.\n",
    "\"\"\"\n",
    "print(\"İlk eğitim örneğinin orijinal hali:\")\n",
    "print(decode_review(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim verisi olan X_train'i makine öğrenmesi modeline uygun hale getirmek için ön işleme tabi tutuyoruz.\n",
    "# Doğal dil işleme uygulamalarında cümleler veya kelime dizileri genellikle farklı uzunluklarda olabilir.\n",
    "# Ancak sinir ağları genellikle sabit boyutlu girdi verilerine ihtiyaç duyar.\n",
    "# Bu nedenle, farklı uzunluklardaki dizileri aynı uzunluğa getirmek için sıfırlama (padding) işlemi yapıyoruz.\n",
    "\n",
    "# pad_sequences fonksiyonu, dizilerin uzunluğunu eşitlemek için kullanılır.\n",
    "# padding='post' parametresi ile, eksik olan öğeleri dizinin SONUNA ekleyerek eşitliyoruz.\n",
    "# Böylece orijinal dizideki verilerin sırası bozulmaz ve veri kaybı olmaz.\n",
    "# Sıfırlama işlemi sonucunda, tüm diziler aynı uzunlukta olup model tarafından işlenebilir hale gelir.\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post')\n",
    "\n",
    "# Test verisi olan X_test'i de aynı şekilde işliyoruz.\n",
    "# Bu, modelin eğitim ve test aşamasında tutarlı ve uyumlu verilerle çalışmasını sağlar.\n",
    "# Aynı sıfırlama işlemi uygulanmazsa, model test verisini doğru bir şekilde değerlendiremeyebilir.\n",
    "\n",
    "X_test = pad_sequences(X_test, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Modeli'nin oluşturulması\n",
    "\"\"\"\n",
    "Bu kod bloğu, duygu analizi için bir sinir LSTM modeli oluşturur.\n",
    "\n",
    "lstm_model (Sequential): Oluşturulan Keras Sequential model\n",
    "\n",
    "Not:\n",
    "\n",
    "    - Model, bir Embedding katmanı, iki LSTM katmanı, bir Dense katman ve bir Dropout katmanından oluşur.\n",
    "    - Embedding katmanı, kelime indekslerini yoğun vektörlere dönüştürür.\n",
    "    - LSTM katmanları, uzun vadeli bağımlılıkları modellemek için kullanılır.\n",
    "    - Dense katman, son sınıflandırma işlemini gerçekleştirir.\n",
    "    - 'sigmoid' aktivasyon fonksiyonu, çıktıyı 0 ile 1 arasında bir olasılığa dönüştürür.\n",
    "    - 'adam' optimizer, modelin eğitimini gerçekleştirir.\n",
    "    - 'binary_crossentropy' loss fonksiyonu, modelin başarısını ölçer.\n",
    "    - 'accuracy' metriği, modelin doğruluğunu ölçer.\n",
    "\"\"\"\n",
    "\n",
    "print(\"LSTM Modeli oluşturuluyor...\")\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(max_index, 32))\n",
    "lstm_model.add(LSTM(64, return_sequences=True))\n",
    "lstm_model.add(LSTM(32))\n",
    "lstm_model.add(Dense(16, activation='relu'))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Modeli'nin oluşturulması\n",
    "\"\"\"\n",
    "Bu kod bloğu, duygu analizi için bir sinir ağı CNN modeli oluşturur.\n",
    "\n",
    "cnn_model (Sequential): Oluşturulan Keras Sequential model\n",
    "\n",
    "Not:\n",
    "    \n",
    "        - Model, bir Embedding katmanı, iki Conv1D katmanı, bir GlobalMaxPooling1D katmanı, iki Dense katman ve bir Dropout katmanından oluşur.\n",
    "        - Embedding katmanı, kelime indekslerini yoğun vektörlere dönüştürür.\n",
    "        - Conv1D katmanları, metin verilerindeki desenleri öğrenmek için kullanılır.\n",
    "        - GlobalMaxPooling1D katmanı, Conv1D katmanlarının çıktılarını düzleştirir.\n",
    "        - Dense katmanlar, sınıflandırma işlemini gerçekleştirir.\n",
    "        - 'sigmoid' aktivasyon fonksiyonu, çıktıyı 0 ile 1 arasında bir olasılığa dönüştürür.\n",
    "        - 'adam' optimizer, modelin eğitimini gerçekleştirir.\n",
    "        - 'binary_crossentropy' loss fonksiyonu, modelin başarısını ölçer.\n",
    "        - 'accuracy' metriği, modelin doğruluğunu ölçer.\n",
    "\"\"\"\n",
    "\n",
    "print(\"CNN Modeli oluşturuluyor...\")\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(max_index, 32))\n",
    "cnn_model.add(Conv1D(64, 5, activation='relu'))\n",
    "cnn_model.add(Conv1D(32, 3, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(16, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Bu kod bloğu, oluşturulan modelin özetini gösterir.\n",
    "Çıktı:\n",
    "    Modelin katmanları, parametreleri ve toplam parametre sayısı hakkında detaylı bilgi\n",
    "\n",
    "Not:\n",
    "    - model.summary() fonksiyonu, modelin yapısını, her katmanın çıktı şeklini ve parametre sayısını gösterir.\n",
    "    - Bu özet, modelin karmaşıklığını ve bellek gereksinimlerini anlamak için çok faydalıdır.\n",
    "\"\"\"\n",
    "print(\"LSTM Modeli:\")\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CNN Modeli:\")\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model eğitme işlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin derlenmesi\n",
    "\"\"\"\n",
    "Bu kod bloğu, oluşturulan modeli derler ve eğitim için hazırlar.\n",
    "Not:\n",
    "    - model.compile() fonksiyonu, modelin eğitim sürecini yapılandırır.\n",
    "    - optimizer='adam': Adam optimizasyon algoritması kullanılacak.\n",
    "    - loss='binary_crossentropy': İkili sınıflandırma için uygun kayıp fonksiyonu.\n",
    "    - metrics=['accuracy']: Eğitim sırasında doğruluk metriği izlenecek.\n",
    "\"\"\"\n",
    "print(\"Modeller derleniyor...\")\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"LSTM modeli derleme tamamlandı.\")\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"CNN modeli derleme tamamlandı.\")\n",
    "print(\"Modelleri derleme tamamlandı.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin eğitilmesi\n",
    "\"\"\"\n",
    "Bu kod bloğu, oluşturulan modeli eğitir.\n",
    "\n",
    "X_train (numpy.ndarray): Eğitim verileri\n",
    "y_train (numpy.ndarray): Eğitim etiketleri\n",
    "history (keras.callbacks.History): Eğitim sürecinin geçmişi\n",
    "\n",
    "Not:\n",
    "    - model.fit() fonksiyonu, modeli verilen veriler üzerinde eğitir.\n",
    "    - epochs=5: Model, veri seti üzerinde 5 kez tekrarlanacak.\n",
    "    - batch_size=128: Her iterasyonda 128 örnek işlenecek.\n",
    "    - validation_split=0.2: Eğitim verilerinin %20'si doğrulama için ayrılacak.\n",
    "    - 1 epoch yaklaşık 3-4 dakika sürdü.\n",
    "\"\"\"\n",
    "print(\"Modeller eğitiliyor...\")\n",
    "print(\"LSTM Modeli eğitiliyor...\")\n",
    "lstm_history = lstm_model.fit(X_train, y_train, epochs=2, batch_size=256, validation_split=0.2)\n",
    "print(\"LSTM Modeli eğitimi tamamlandı.\")\n",
    "print(\"CNN Modeli eğitiliyor...\")\n",
    "cnn_history = cnn_model.fit(X_train, y_train, epochs=2, batch_size=256, validation_split=0.2)\n",
    "print(\"CNN Modeli eğitimi tamamlandı.\")\n",
    "print(\"Model eğitim tamamlandı.\")\n",
    "lstm_history.history, cnn_history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelin değerlendirilmesi\n",
    "\n",
    "\"\"\"\n",
    "Bu kod bloğu, eğitilmiş modeli test veri seti üzerinde değerlendirir.\n",
    "\n",
    "Çıktı:\n",
    "    - Test Loss: Modelin test veri seti üzerindeki kayıp değeri\n",
    "    - Test Accuracy: Modelin test veri seti üzerindeki doğruluk oranı\n",
    "\n",
    "Not:\n",
    "    - model.evaluate() fonksiyonu, modeli verilen veri seti üzerinde değerlendirir.\n",
    "    - Kayıp (loss) değeri, modelin tahminlerinin gerçek değerlerden ne kadar uzak olduğunu gösterir.\n",
    "    - Doğruluk (accuracy) değeri, modelin doğru tahmin ettiği örneklerin oranını gösterir.\n",
    "    - Yaklaşık 4 dakika sürer.\n",
    "\"\"\"\n",
    "print(\"Modeller test verisi üzerinde değerlendiriliyor...\")\n",
    "print(\"LSTM Modeli değerlendiriliyor...\")\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_test, y_test)\n",
    "print(\"LSTM Modeli değerlendirme tamamlandı.\")\n",
    "print(\"CNN Modeli değerlendiriliyor...\")\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "print(\"CNN Modeli değerlendirme tamamlandı.\")\n",
    "print(\"Modeller değerlendirme tamamlandı.\")\n",
    "print(f\"LSTM Modeli - Test Loss: {lstm_loss}, Test Accuracy: {lstm_accuracy}\")\n",
    "print(f\"CNN Modeli - Test Loss: {cnn_loss}, Test Accuracy: {cnn_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeli elle test etme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonksiyon tanımları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_review():\n",
    "    \"\"\"\n",
    "    Kullanıcıdan film yorumu alır.\n",
    "\n",
    "    Returns:\n",
    "        str: Kullanıcının girdiği film yorumu\n",
    "\n",
    "    Not:\n",
    "        - Kullanıcıya bir giriş istemi sunar.\n",
    "        - 'q' girişi, programdan çıkış için kullanılır.\n",
    "    \"\"\"\n",
    "    return input(\"Lütfen bir film yorumu girin (Çıkmak için 'q' yazın): \")\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Metni kelimelere ayırır.\n",
    "\n",
    "    Args:\n",
    "        text (str): İşlenecek metin\n",
    "\n",
    "    Returns:\n",
    "        list: Metindeki kelimelerin listesi\n",
    "\n",
    "    Not:\n",
    "        - Keras'ın text_to_word_sequence fonksiyonunu kullanır.\n",
    "        - Bu fonksiyon, metni küçük harflere çevirir, noktalama işaretlerini kaldırır ve kelimelere ayırır.\n",
    "    \"\"\"\n",
    "    return keras.preprocessing.text.text_to_word_sequence(text)\n",
    "\n",
    "def tokenize_words(tokens):\n",
    "    \"\"\"\n",
    "    Kelimeleri sayısal indekslere dönüştürür.\n",
    "\n",
    "    Args:\n",
    "        tokens (list): Kelime listesi\n",
    "\n",
    "    Returns:\n",
    "        list: Kelimelerin sayısal indeks karşılıkları\n",
    "\n",
    "    Not:\n",
    "        - word_index sözlüğünü kullanarak her kelimeyi bir sayıya dönüştürür.\n",
    "        - Sözlükte olmayan kelimeler için 1 değerini kullanır (genellikle bilinmeyen kelime indeksi).\n",
    "    \"\"\"\n",
    "    return [word_index.get(word, 1) for word in tokens]\n",
    "\n",
    "def limit_token_range(tokens):\n",
    "    \"\"\"\n",
    "    Token değerlerini 10000'in altında tutar.\n",
    "\n",
    "    Args:\n",
    "        tokens (list): Sayısal token listesi\n",
    "\n",
    "    Returns:\n",
    "        list: 10000'in altındaki değerlere sınırlandırılmış token listesi\n",
    "\n",
    "    Not:\n",
    "        - 10000'den büyük indeksleri 1'e çevirir.\n",
    "        - Bu, modelin kelime dağarcığı boyutunu sınırlar ve aşırı büyük indeksleri engeller.\n",
    "    \"\"\"\n",
    "    return [t if t < max_index else 1 for t in tokens]\n",
    "\n",
    "def pad_tokens(tokens):\n",
    "    \"\"\"\n",
    "    Token dizisini sabit uzunluğa getirir.\n",
    "\n",
    "    Args:\n",
    "        tokens (list): Sayısal token listesi\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Sabit uzunluğa getirilmiş token dizisi\n",
    "\n",
    "    Not:\n",
    "        - Keras'ın pad_sequences fonksiyonunu kullanır.\n",
    "        - maxlen değişkeni, dizinin hedef uzunluğunu belirtir.\n",
    "        - Kısa diziler 0 ile doldurulur, uzun diziler kesilir.\n",
    "    \"\"\"\n",
    "    return pad_sequences([tokens], maxlen=max_index)\n",
    "\n",
    "def encode_review(text):\n",
    "    \"\"\"\n",
    "    Yorumu model için uygun formata dönüştürür.\n",
    "\n",
    "    Args:\n",
    "        text (str): Orijinal yorum metni\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Model için hazırlanmış, kodlanmış yorum\n",
    "\n",
    "    Not:\n",
    "        - Metni işlemek için önceki fonksiyonları sırayla çağırır.\n",
    "        - Son çıktı, modelin beklediği formatta bir numpy dizisidir.\n",
    "    \"\"\"\n",
    "    tokens = preprocess_text(text)\n",
    "    tokens = tokenize_words(tokens)\n",
    "    tokens = limit_token_range(tokens)\n",
    "    return pad_tokens(tokens)\n",
    "\n",
    "def predict_sentiment(encoded_review, model):\n",
    "    \"\"\"\n",
    "    Kodlanmış yorum için duygu tahmini yapar.\n",
    "\n",
    "    Args:\n",
    "        encoded_review (numpy.ndarray): Kodlanmış yorum\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Modelin tahmin sonucu\n",
    "\n",
    "    Not:\n",
    "        - Önceden eğitilmiş modeli kullanarak tahmin yapar.\n",
    "        - Sonuç, yorumun pozitif olma olasılığını içerir.\n",
    "    \"\"\"\n",
    "    return model.predict(encoded_review)\n",
    "\n",
    "def print_prediction(review, lstm_prediction, cnn_prediction):\n",
    "    \"\"\"\n",
    "    Tahmin sonucunu ekrana yazdırır.\n",
    "\n",
    "    Args:\n",
    "        review (str): Orijinal yorum metni\n",
    "        lstm_prediction (numpy.ndarray): LSTM modelinin tahmin sonucu\n",
    "        cnn_prediction (numpy.ndarray): CNN modelinin tahmin sonucu\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Not:\n",
    "        - Orijinal yorumu ve pozitif olma olasılığını yazdırır.\n",
    "        - Olasılık 4 ondalık basamağa yuvarlanır.\n",
    "    \"\"\"\n",
    "    print(f\"\\nYorum: {review}\")\n",
    "    print(f\"LSTM Modeli Tahmini: %{lstm_prediction[0][0]*100:.4f}\")\n",
    "    print(f\"CNN Modeli Tahmini: %{cnn_prediction[0][0]*100:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elle test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Film yorumları için duygu analizi uygulaması başlatılıyor...\")\n",
    "while True:\n",
    "    review = get_user_review()\n",
    "    if review.lower() == 'q':\n",
    "        print(\"Uygulama sonlandırılıyor...\")\n",
    "        break\n",
    "    \n",
    "    encoded_review = encode_review(review)\n",
    "    lstm_prediction = predict_sentiment(encoded_review, lstm_model)\n",
    "    cnn_prediction = predict_sentiment(encoded_review, cnn_model)\n",
    "    print_prediction(review, lstm_prediction, cnn_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
